<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Projects - Milad Soleymani</title>
  <meta name="description"
    content="Research projects by Milad Soleymani in AI, machine learning, EEG processing, and computer vision.">
  <meta name="keywords" content="AI projects, machine learning, EEG, BCI, computer vision, medical AI">
  <meta name="author" content="Milad Soleymani">

  <!--
    - favicon
  -->
  <link rel="shortcut icon" href="./assets/images/logo.ico" type="image/x-icon">

  <!--
    - custom css link
  -->
  <link rel="stylesheet" href="./assets/css/style.css">

  <!--
    - google font link
  -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">
</head>

<body>

  <!--
    - #MAIN
  -->

  <main>

    <!--
      - #SIDEBAR
    -->

    <aside class="sidebar" data-sidebar>

      <div class="sidebar-info">

        <figure class="avatar-box">
          <img src="./assets/images/profile_pic.png" alt="Milad Soleymani" width="80">
        </figure>

        <div class="info-content">
          <h1 class="name" title="Milad Soleymani">Milad Soleymani</h1>

          <p class="title">AI/ML Researcher</p>
        </div>

        <button class="info_more-btn" data-sidebar-btn>
          <span>Show Contacts</span>

          <ion-icon name="chevron-down"></ion-icon>
        </button>

      </div>

      <div class="sidebar-info_more">

        <div class="separator"></div>

        <ul class="contacts-list">

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="mail-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Email</p>

              <a href="mailto:miladsoleiimani@gmail.com" class="contact-link">miladsoleiimani@gmail.com</a>
            </div>

          </li>

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="phone-portrait-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Phone</p>

              <span class="contact-link">Available upon request</span>
            </div>

          </li>

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="calendar-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Education</p>

              <span>M.Sc. AI & Robotics</span>
            </div>

          </li>

          <li class="contact-item">

            <div class="icon-box">
              <ion-icon name="location-outline"></ion-icon>
            </div>

            <div class="contact-info">
              <p class="contact-title">Location</p>

              <address>Tehran, Iran</address>
            </div>

          </li>

        </ul>

        <div class="separator"></div>

        <ul class="social-list">

          <li class="social-item">
            <a href="https://github.com/miladsoleymani" class="social-link">
              <ion-icon name="logo-github"></ion-icon>
            </a>
          </li>

          <li class="social-item">
            <a href="https://linkedin.com/in/miladsoleymani" class="social-link">
              <ion-icon name="logo-linkedin"></ion-icon>
            </a>
          </li>

          <li class="social-item">
            <a href="https://scholar.google.com/citations?user=YOUR_SCHOLAR_ID" class="social-link">
              <ion-icon name="school-outline"></ion-icon>
            </a>
          </li>

        </ul>

      </div>

    </aside>

    <!--
      - #main-content
    -->

    <div class="main-content">

      <!--
        - #NAVBAR
      -->

      <nav class="navbar">

        <ul class="navbar-list">

          <li class="navbar-item">
            <a href="index.html" class="navbar-link">About</a>
          </li>

          <li class="navbar-item">
            <a href="resume.html" class="navbar-link">Resume</a>
          </li>

          <li class="navbar-item">
            <a href="projects.html" class="navbar-link active">Projects</a>
          </li>

          <li class="navbar-item">
            <a href="publications.html" class="navbar-link">Publications</a>
          </li>

          <li class="navbar-item">
            <a href="contact.html" class="navbar-link">Contact</a>
          </li>

        </ul>

      </nav>

      <!--
        - #PORTFOLIO
      -->

      <article class="portfolio active" data-page="projects">

        <header>
          <h2 class="h2 article-title">Projects</h2>
        </header>

        <section class="projects">

          <ul class="project-list">

            <li class="project-item active" data-filter-item data-category="computer vision">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-computer-vision.svg" alt="Computer Vision" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Video Segmentation Tool</h3>
                  <p class="project-category">Computer Vision</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> A semi-automatic video segmentation tool that accelerates the
                      preparation of image segmentation data for video sequences using GUI-based annotation and AI
                      propagation.</p>

                    <p><strong>Technologies:</strong> Python, PyQt6, PyTorch, OpenCV, OSVOS (One-Shot Video Object
                      Segmentation)</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Manual annotation tools (pencil, polygon)</li>
                      <li>• Semi-automatic label propagation using Optical Flow and OSVOS</li>
                      <li>• Frame-by-frame navigation with multi-label support</li>
                      <li>• MVC architecture for scalable design</li>
                    </ul>

                    <p><strong>Impact:</strong> Combines manual annotation capabilities with automated segmentation
                      algorithms to significantly reduce manual labeling effort for video datasets.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/video_segmentation_tool" target="_blank"
                        class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>

            <li class="project-item active" data-filter-item data-category="computer vision">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-computer-vision.svg" alt="Computer Vision" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Skin Cancer Detection</h3>
                  <p class="project-category">Computer Vision</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> A comprehensive medical AI system for skin cancer detection using Swin
                      Transformer with parameter-efficient bottleneck adapters. Supports both binary classification
                      (benign vs malignant) and multiclass classification (HAM10000 7-class dataset) for clinical-grade
                      dermatoscopic image analysis.</p>

                    <p><strong>Technologies:</strong> Python, PyTorch, Swin Transformer, Vision Transformer (ViT),
                      Parameter-Efficient Fine-Tuning, Bottleneck Adapters, Medical Imaging</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Parameter-efficient fine-tuning with bottleneck adapters</li>
                      <li>• Swin Transformer and ViT architectures for medical imaging</li>
                      <li>• Binary and 7-class classification capabilities</li>
                      <li>• HAM10000 dataset integration for dermatoscopic analysis</li>
                    </ul>

                    <p><strong>Impact:</strong> Advances dermatological AI by combining efficient transfer learning
                      techniques with state-of-the-art vision transformers for accurate skin cancer detection and
                      classification in clinical settings.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/skin-cancer" target="_blank" class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>


            <li class="project-item active" data-filter-item data-category="computer vision">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-computer-vision.svg" alt="Computer Vision" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Face Demography Analysis</h3>
                  <p class="project-category">Computer Vision</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> A real-time facial emotion detection system using YOLOv8 for face
                      detection and FER for emotion analysis across 7 categories.</p>

                    <p><strong>Technologies:</strong> Python, YOLOv8, OpenCV, Facial Expression Recognition (FER), ONNX
                    </p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Real-time emotion recognition across 7 categories</li>
                      <li>• Multiple input sources (images, videos, webcam)</li>
                      <li>• Two-stage detection pipeline</li>
                      <li>• Command-line interface with flexible parameters</li>
                    </ul>

                    <p><strong>Applications:</strong> Combines YOLOv8 face detection with emotion recognition algorithms
                      for real-time video streams, suitable for demographic analysis and human-computer interaction
                      applications.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/Face_Demography" target="_blank" class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>



            <li class="project-item active" data-filter-item data-category="signal processing">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-signal-processing.svg" alt="Signal Processing" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Baseline Models for EEG Analysis</h3>
                  <p class="project-category">Signal Processing</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> A comprehensive framework for EEG signal analysis and classification,
                      providing baseline implementations of classical machine learning models for the research
                      community.</p>

                    <p><strong>Technologies:</strong> Python, NumPy, SciPy, scikit-learn, PyTorch, MNE-Python, XGBoost
                    </p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Support for multiple EEG datasets (CHB-MIT, BCI Competition 2a, LEE, Klinik)</li>
                      <li>• Classical ML models with signal processing techniques</li>
                      <li>• Modular architecture with cross-validation</li>
                      <li>• Integration with Weights & Biases for experiment tracking</li>
                    </ul>

                    <p><strong>Impact:</strong> Provides standardized framework for EEG signal processing including
                      epilepsy detection and motor imagery classification with reproducible baseline performance metrics
                      across different datasets.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/baseline_models_eeg" target="_blank"
                        class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>


            <li class="project-item active" data-filter-item data-category="signal processing">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-signal-processing.svg" alt="Signal Processing" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Vibration Noise Detection</h3>
                  <p class="project-category">Signal Processing</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> Signal processing system for detecting and analyzing vibration-induced
                      noise patterns using machine learning techniques and acoustic signal analysis.</p>

                    <p><strong>Technologies:</strong> Python, Signal Processing, Machine Learning, Audio Analysis,
                      Spectral Analysis</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Vibration pattern recognition and classification</li>
                      <li>• Spectral analysis for noise characterization</li>
                      <li>• Real-time signal processing capabilities</li>
                      <li>• Anomaly detection in mechanical systems</li>
                    </ul>

                    <p><strong>Applications:</strong> Enables predictive maintenance and fault detection in mechanical
                      systems by analyzing vibration signatures and identifying abnormal noise patterns for industrial
                      monitoring.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/vibration_noise_detection" target="_blank"
                        class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>


            <li class="project-item active" data-filter-item data-category="signal processing">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-signal-processing.svg" alt="Signal Processing" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Self-supervised EEG Embedding</h3>
                  <p class="project-category">Signal Processing</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> Learn meaningful EEG representations without labeled data across
                      multiple tasks and datasets using self-supervised learning techniques.</p>

                    <p><strong>Technologies:</strong> PyTorch Lightning, Python, Neural Networks, EEG Signal Processing
                    </p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Self-supervised learning framework for EEG</li>
                      <li>• Task-agnostic embeddings for multiple datasets</li>
                      <li>• Modular neural architecture with "Minion Networks"</li>
                      <li>• Cross-validation support for robust evaluation</li>
                    </ul>

                    <p><strong>Impact:</strong> Creates transferable embeddings across different neurological signal
                      analysis tasks using auxiliary tasks like temporal context prediction and channel reconstruction.
                    </p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/Self-supervised-Task-agnostic-EEG-Embedding"
                        target="_blank" class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>


            <li class="project-item active" data-filter-item data-category="signal processing">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-signal-processing.svg" alt="Signal Processing" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">EEG-LTENT</h3>
                  <p class="project-category">Signal Processing</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> EEG-LTENT (Learned Task-agnostic Embeddings for Neural Time-series)
                      provides a foundation model approach for EEG signal analysis. Instead of training task-specific
                      models from scratch, this framework learns universal EEG representations that can be fine-tuned
                      for various downstream applications.</p>

                    <p><strong>Technologies:</strong> Python, PyTorch, Conformer Architecture, Vector Quantization,
                      Masked Autoencoding, Self-Supervised Learning, CNN-Transformer Hybrid</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Task-agnostic learning: Pre-train once, adapt to many tasks (classification, regression,
                        clustering)</li>
                      <li>• Self-supervised approach using masked autoencoding on unlabeled EEG data</li>
                      <li>• Discrete representations through vector quantization for interpretable embedding spaces</li>
                      <li>• Universal embeddings that transfer across datasets, tasks, and subjects</li>
                    </ul>

                    <p><strong>Impact:</strong> Revolutionizes EEG analysis by creating a foundation model that learns
                      from unlabeled data and transfers knowledge across different neurological tasks, significantly
                      improving performance on limited labeled datasets.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/EEG-LTENT" target="_blank" class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>

            <li class="project-item active" data-filter-item data-category="computer vision">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-computer-vision.svg" alt="Computer Vision" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Image Captioning</h3>
                  <p class="project-category">Computer Vision</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> A comprehensive image captioning system that automatically generates
                      descriptive text for images using deep learning techniques and attention mechanisms.</p>

                    <p><strong>Technologies:</strong> Python, PyTorch, Computer Vision, Natural Language Processing,
                      CNN, RNN, Attention</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Encoder-decoder architecture with attention mechanism</li>
                      <li>• CNN-based image feature extraction</li>
                      <li>• RNN-based text generation</li>
                      <li>• Multi-modal learning approach</li>
                    </ul>

                    <p><strong>Impact:</strong> Bridges computer vision and natural language processing to generate
                      human-like descriptions of visual content for accessibility and automated content description
                      applications.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/Image-captioning" target="_blank" class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>


            <li class="project-item active" data-filter-item data-category="nlp">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/10129318.png" alt="NLP" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">PDF-QA using LLM</h3>
                  <p class="project-category">NLP</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> A Python application that processes PDF documents and extracts
                      structured information using Large Language Models, designed specifically for medical reports.</p>

                    <p><strong>Technologies:</strong> OpenAI GPT, Meta's LLaMA, Python, PyTorch, Hugging Face
                      Transformers, LangChain</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Dual LLM support (GPT and LLaMA)</li>
                      <li>• Automated PDF content extraction with structured output</li>
                      <li>• Batch processing capabilities</li>
                      <li>• Resource usage monitoring</li>
                    </ul>

                    <p><strong>Impact:</strong> Uses large language models to parse PDF files and extract patient
                      information, test results, and panel summaries with flexible LLM backends and structured CSV/JSON
                      outputs.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/PDF-QA-using-LLM" target="_blank" class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>


            <li class="project-item active" data-filter-item data-category="nlp">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/10129318.png" alt="NLP" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Persian Text Classification using GloVe</h3>
                  <p class="project-category">NLP</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> Classify ten classes of Persian text datasets using GloVe embedding to
                      address unique challenges of Persian language processing in multi-class classification.</p>

                    <p><strong>Technologies:</strong> Python, Jupyter Notebook, GloVe Embedding, Machine Learning</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Multi-class Persian text classification framework</li>
                      <li>• GloVe word embedding implementation for Persian</li>
                      <li>• Comprehensive preprocessing pipeline</li>
                      <li>• Specialized handling of Persian language characteristics</li>
                    </ul>

                    <p><strong>Applications:</strong> Leverages GloVe embeddings to convert Persian text into numerical
                      representations for effective machine learning classification across ten distinct text categories.
                    </p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/Persian-text-classification-using-glove-embedding"
                        target="_blank" class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>


            <li class="project-item active" data-filter-item data-category="computer vision">
              <div class="project-content">
                <figure class="project-img">
                  <div class="project-item-icon-box">
                    <ion-icon name="eye-outline"></ion-icon>
                  </div>
                  <img src="./assets/images/icon-computer-vision.svg" alt="Computer Vision" loading="lazy">
                </figure>

                <div class="project-details">
                  <h3 class="project-title">Tumor Classification Using Machine Learning</h3>
                  <p class="project-category">Computer Vision</p>

                  <div class="project-description">
                    <p><strong>Overview:</strong> A comprehensive machine learning project for tumor subtype
                      classification using mutation and copy number variation data from genomic analysis.</p>

                    <p><strong>Technologies:</strong> Python, Scikit-learn, Pandas, NumPy, Jupyter Notebook, Deep Neural
                      Networks</p>

                    <p><strong>Key Features:</strong></p>
                    <ul>
                      <li>• Classification of tumor subtypes (PDM vs SCM)</li>
                      <li>• Multiple ML approaches including SVM, XGBoost, and few-shot learning</li>
                      <li>• Feature selection and dimensionality reduction techniques</li>
                      <li>• 5-fold cross-validation evaluation</li>
                    </ul>

                    <p><strong>Results:</strong> Achieved 69.17% accuracy with Logistic Regression using Tumor Mutation
                      Burden, copy number variations, and missense mutations with metaheuristic optimization for feature
                      selection.</p>

                    <div class="project-links">
                      <a href="https://github.com/MiladSoleymani/tumur-classification" target="_blank"
                        class="project-link">
                        <ion-icon name="logo-github"></ion-icon> View on GitHub
                      </a>
                    </div>
                  </div>
                </div>
              </div>
            </li>
          </ul>

        </section>

      </article>

    </div>

  </main>

  <!--
    - custom js link
  -->
  <script src="./assets/js/script.js"></script>

  <!--
    - ionicon link
  -->
  <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

</body>

</html>